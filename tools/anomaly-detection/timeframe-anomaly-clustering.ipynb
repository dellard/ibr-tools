{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (C) 2020-2024 - Raytheon BBN Technologies Corp.\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "\n",
    "You may obtain a copy of the License at\n",
    "http://www.apache.org/licenses/LICENSE-2.0.\n",
    "\n",
    "Unless required by applicable law or agreed to in writing,\n",
    "software distributed under the License is distributed on an\n",
    "\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND,\n",
    "either express or implied. See the License for the specific\n",
    "language governing permissions and limitations under the License.\n",
    "\n",
    "Distribution Statement \"A\" (Approved for Public Release,\n",
    "Distribution Unlimited).\n",
    "\n",
    "This material is based upon work supported by the Defense\n",
    "Advanced Research Projects Agency (DARPA) under Contract No.\n",
    "HR001119C0102.  The opinions, findings, and conclusions stated\n",
    "herein are those of the authors and do not necessarily reflect\n",
    "those of DARPA.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Timeframe Anomaly Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-07T16:01:29.984747908Z",
     "start_time": "2023-07-07T16:01:21.967013753Z"
    }
   },
   "outputs": [],
   "source": [
    "import ipaddress\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import yaml\n",
    "from src.TrafficShapeAnalysis import TrafficShapeAnalysis\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Defined Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the parameter file `config.yml`, Specify the user defined parameters. The descriptions of the paramters are in the file\n",
    "\n",
    "Run the cell below to load the parameters from `config.yml` and to populate a set of destination addresses from a destination subnet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-07T16:01:32.603652569Z",
     "start_time": "2023-07-07T16:01:32.522793238Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load parameters from config.yml - Parameter descriptions are specified in the yaml file\n",
    "with open('config.yml', 'r') as file:\n",
    "    params = yaml.safe_load(file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization of Variables and Function Declarations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug = params['debug']\n",
    "save_figs = params['save_figs']\n",
    "compute_features = params['compute_features']\n",
    "previous_features = str(params['previous_features'])\n",
    "clustering_alg = str(params['clustering_alg'])\n",
    "num_clusters = params['num_clusters'] \n",
    "quantile = params['quantile'] \n",
    "linkage = params['linkage'] \n",
    "save_features = params['save_features']\n",
    "limit_val = params['limit_val']\n",
    "output_dir_path = params['output_dir_path']\n",
    "\n",
    "# Transform the list of subnets to a set of IP addresses\n",
    "destination_addresses = set()\n",
    "for i in params['destination_subnets']:\n",
    "    ll = [str(ip) for ip in ipaddress.IPv4Network(i)]\n",
    "    destination_addresses.update(ll)\n",
    "\n",
    "vals_of_interest = ['val0', 'val1', 'val2', 'val3', 'val4', 'delta0', 'delta1', 'delta2', 'delta3', 'delta4']\n",
    "\n",
    "if(output_dir_path[len(output_dir_path)-1] != '/'):\n",
    "    output_dir_path = output_dir_path + '/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function used for sampling values from a specific \n",
    "def sample_cluster_pca_vals(vals_of_interest, sources, pca_values, limit_val):\n",
    "    \n",
    "    curr_cluster_vals = pd.DataFrame(columns = vals_of_interest)\n",
    "    \n",
    "    # Sample upto limit_val packets for each source\n",
    "    for source in sources:\n",
    "        \n",
    "        curr_source = pca_values[pca_values['ip'] == source]\n",
    "        if len(curr_source) > limit_val:\n",
    "            curr_source = curr_source.sample(limit_val)\n",
    "    \n",
    "        curr_cluster_vals = pd.concat([curr_cluster_vals, curr_source[vals_of_interest]], axis=0)\n",
    "        \n",
    "    return curr_cluster_vals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the Features Using `TrafficShapeAnalysis` Object\n",
    "\n",
    "Run the cell below to either compute or load previously computed Features\n",
    "\n",
    "If you are computing the features this will initialize a new `TrafficShapeAnalysis` object and then compute the features This can take a long time because for each packet, features are being calculated and the data is undergoing interpolation and dimensionality reduction. While the object is initializing, you can see how many packets with the specified protocol and destination subnet have been processed.\n",
    "\n",
    "If you are loading previously computed features, it will load them into a new `TrafficShapeAnalysis` object and it could be very fast or very slow depending on how many points you have in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-07T16:04:04.098183142Z",
     "start_time": "2023-07-07T16:01:35.413755144Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "init_time = time.time()\n",
    "\n",
    "# Compute Features\n",
    "if compute_features == 1:\n",
    "    print('Computing Features')\n",
    "    traffic_analysis = TrafficShapeAnalysis(path_to_csv=params['path_to_csv'],\n",
    "                                            csv_filenames=params['csv_files'],\n",
    "                                            output_filename=params['output_file'],\n",
    "                                            destination_sources=destination_addresses,\n",
    "                                            traffic_type=params['traffic_type'],\n",
    "                                            max_states=params['max_states'],\n",
    "                                            interpolation_n=params['interpolation_n'],\n",
    "                                            show_pc_plot=False)\n",
    "\n",
    "    if debug == 1:\n",
    "        print(f\"Total time: {time.time() - init_time}\")\n",
    "        \n",
    "#Load previously computed features\n",
    "else:\n",
    "    print('Loading Previous Features')\n",
    "    traffic_analysis = TrafficShapeAnalysis(pc_values_csv=previous_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster the Data\n",
    "The data can be clustered using agglomerative, mean shift, or spectral clustering. The selection of the algorithm and setting the algorithm parameters is done in the configuration file `config.yml`\n",
    "\n",
    "1. <b> Mean Shift Clustering:</b> \n",
    "The `quantile` parameter must be specified.\n",
    "\n",
    "2. <b> Agglomerative Clustering:</b> \n",
    "The `n_clusters` and the `linkage` parameters must be specificed. Appropriate values for `linkage` are 'single', 'average', or 'complete' ('average' recommended if you don't want to optimize the parameters).\n",
    "\n",
    "3. <b> Spectral Clustering: </b> \n",
    "The `n_clusters` parameter must be specified.\n",
    "\n",
    "\n",
    "This will print clustering metrics, including the Silhouette Coefficient and the Davies-Bouldin Index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-07T16:05:31.278219347Z",
     "start_time": "2023-07-07T16:05:27.599737309Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f'Running {clustering_alg} clustering')\n",
    "if clustering_alg == \"MeanShift\":\n",
    "    # Mean shift clustering\n",
    "    cluster_dict = traffic_analysis.cluster(clustering_alg, quantile=quantile, in_dict=True, labels=True, return_cluster_object=True)\n",
    "elif clustering_alg == \"Agglomerative\":\n",
    "    cluster_dict = traffic_analysis.cluster(clustering_alg, n_clusters=num_clusters, linkage=linkage, in_dict=True, labels=True)\n",
    "elif clustering_alg == \"Spectral\":\n",
    "    cluster_dict = traffic_analysis.cluster(clustering_alg, n_clusters=num_clusters, in_dict=True, labels=True)\n",
    "else:\n",
    "    sys.exit(\"Please specify the correct algorithm\")\n",
    "    \n",
    "if debug == 1:\n",
    "    print('cluster_dict: ', cluster_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_numbers = sorted(list(cluster_dict.keys()))\n",
    "if debug == 1:\n",
    "    print(\"Cluster Numbers = \", cluster_numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bar Charts of Number of Source Addresses in each Cluster\n",
    "Run the cell below to view how many source addresses are in each cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-07T16:05:36.280928615Z",
     "start_time": "2023-07-07T16:05:35.754987373Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plotting bar charts\n",
    "\n",
    "source_counts = [len(cluster_dict[n]) for n in cluster_numbers]\n",
    "\n",
    "plt.bar(cluster_numbers, source_counts, alpha=0.5, align='center')\n",
    "plt.ylabel('Count of Source Addresses')\n",
    "plt.xlabel('Cluster Number')\n",
    "\n",
    "if clustering_alg == \"MeanShift\":\n",
    "    plt.title(f'Sources per Cluster with {clustering_alg} Clustering, quantile = {quantile}')\n",
    "    plt.tight_layout()\n",
    "    if save_figs == 1:\n",
    "        plt.savefig(f'{output_dir_path}{clustering_alg}_quantile_{quantile}.png')\n",
    "elif clustering_alg == \"Agglomerative\":\n",
    "    plt.title(f'Sources per Cluster with {clustering_alg} Clustering, num_clusters ={num_clusters} and linkage = {linkage}')\n",
    "    plt.tight_layout()\n",
    "    if save_figs == 1:\n",
    "        plt.savefig(f'{output_dir_path}{clustering_alg}_num_clusters_{num_clusters}_linkage_{linkage}.png')\n",
    "elif clustering_alg == \"Spectral\":\n",
    "    plt.title(f'Sources per Cluster with {clustering_alg} Clustering, num_clusters ={num_clusters}')\n",
    "    plt.tight_layout()\n",
    "    if save_figs == 1:\n",
    "        plt.savefig(f'{output_dir_path}{clustering_alg}_num_clusters_{num_clusters}.png')\n",
    "\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_values = traffic_analysis.sources_pcs_df\n",
    "# Axis labels, which are the first three principal component values.\n",
    "idx, idy, idz = \"val0\", \"val1\", \"val2\"\n",
    "\n",
    "plot_vals_of_interest = [idx, idy, idz]\n",
    "\n",
    "num_clusters = len(cluster_numbers)\n",
    "\n",
    "x_min = pca_values[idx].min()\n",
    "x_max = pca_values[idx].max()\n",
    "y_min = pca_values[idy].min()\n",
    "y_max = pca_values[idy].max()\n",
    "z_min = pca_values[idz].min()\n",
    "z_max = pca_values[idz].max()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Individual Clusters in 3D\n",
    "Each cluster can be visualized in 3D using the first three principal components (PCs). These PCs do not have any meaning, but they hold the most meaningful parts (most variation) of the original data.\n",
    "\n",
    "Note: some clusters may look similar, however, they may still be different as all the values are not being plotted here. Internally 5 principal components are beiny used to compute the clusters. However, only the top 3 most important principal components are being plotted\n",
    "\n",
    "Note: If there are too many packets/source, then only the max `limit_val` packets from config file are plotted for each source\n",
    "\n",
    "Run the cell that plots the data. You should get several plots, one for each cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-07T16:05:47.486670092Z",
     "start_time": "2023-07-07T16:05:39.684507053Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plotting each cluster separately\n",
    "\n",
    "for cluster_n in cluster_numbers:\n",
    "    sources = cluster_dict[cluster_n]\n",
    "#     print(sources)\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    # Plot up to 200 packets for each source\n",
    "    for source in sources:\n",
    "        curr_pca_values = pca_values[pca_values['ip'] == source]\n",
    "        if len(curr_pca_values) > limit_val:\n",
    "            curr_pca_values = curr_pca_values.sample(limit_val)\n",
    "\n",
    "        ax.scatter(curr_pca_values[idx], curr_pca_values[idy], curr_pca_values[idz], s=5, label=source)\n",
    "\n",
    "    ax.set_xlabel(idx)\n",
    "    ax.set_ylabel(idy)\n",
    "    ax.set_zlabel(idz)\n",
    "\n",
    "    ax.axes.set_xlim3d(left=x_min, right=x_max)\n",
    "    ax.axes.set_ylim3d(bottom=y_min, top=y_max)\n",
    "    ax.axes.set_zlim3d(bottom=z_min, top=z_max)\n",
    "\n",
    "    plt.legend()\n",
    "\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    # Sort both labels and handles by labels\n",
    "    labels, handles = zip(*sorted(zip(labels, handles), key=lambda t: t[0]))\n",
    "    ax.legend(handles, labels)\n",
    "    \n",
    "    if clustering_alg == \"MeanShift\":\n",
    "        plt.title(f\"{clustering_alg} Clustering, quantile = {quantile}', Cluster {cluster_n}, Sources: {len(sources)}\")\n",
    "        if save_figs == 1:\n",
    "            plt.savefig(f'{output_dir_path}{clustering_alg}_quantile_{quantile}cluster_n{cluster_n}.png')\n",
    "    elif clustering_alg == \"Agglomerative\":\n",
    "        plt.title(f\"{clustering_alg} Clustering, num_clusters ={num_clusters}, linkage = {linkage}, Cluster {cluster_n}, Sources: {len(sources)}\")\n",
    "        if save_figs == 1:\n",
    "            plt.savefig(f'{output_dir_path}{clustering_alg}_num_clusters_{num_clusters}_linkage_{linkage}_cluster_n{cluster_n}.png')\n",
    "    elif clustering_alg == \"Spectral\":\n",
    "        plt.title(f\"{clustering_alg} Clustering, num_clusters ={num_clusters}, Cluster {cluster_n}, Sources: {len(sources)}\")\n",
    "        if save_figs == 1:\n",
    "            plt.savefig(f'{output_dir_path}{clustering_alg}_num_clusters_{num_clusters}_cluster_n{cluster_n}.png')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All Clusters in 3D\n",
    "Clusters can be visualized in 3D using the first three principal components (PCs). These PCs do not have any meaning, but they hold the most meaningful parts (most variation) of the original data.\n",
    "\n",
    "Note: some clusters may look similar, however, they may still be different as all the values are not being plotted here. Internally 5 principal components are beiny used to compute the clusters. However, only the top 3 most important principal components are being plotted\n",
    "\n",
    "Note: If there are too many packets/source, then only the max `limit_val` packets from config file are plotted for each source\n",
    "\n",
    "Run the cell that plots the data. You should get with one plot of all the clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting all the clusters together\n",
    "\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "for cluster_n in cluster_numbers:\n",
    "    sources = cluster_dict[cluster_n]\n",
    "    sample_cluster_vals = sample_cluster_pca_vals(plot_vals_of_interest, sources, pca_values, limit_val)\n",
    "    ax.scatter(sample_cluster_vals[idx], sample_cluster_vals[idy], sample_cluster_vals[idz], s=5, label=f'Cluster {cluster_n}')\n",
    "\n",
    "ax.set_xlabel(idx)\n",
    "ax.set_ylabel(idy)\n",
    "ax.set_zlabel(idz)\n",
    "\n",
    "ax.axes.set_xlim3d(left=x_min, right=x_max)\n",
    "ax.axes.set_ylim3d(bottom=y_min, top=y_max)\n",
    "ax.axes.set_zlim3d(bottom=z_min, top=z_max)\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "# Sort both labels and handles by labels\n",
    "labels, handles = zip(*sorted(zip(labels, handles), key=lambda t: t[0]))\n",
    "ax.legend(handles, labels)\n",
    "plt.title(f\"All the {num_clusters} clusters with {clustering_alg} Clustering\")\n",
    "\n",
    "if clustering_alg == \"MeanShift\":\n",
    "    plt.title(f\"All the {num_clusters} {clustering_alg} clusters\")\n",
    "    if save_figs == 1:\n",
    "        plt.savefig(f'{output_dir_path}{clustering_alg}_quantile_{quantile}_all_Clusters.png')\n",
    "elif clustering_alg == \"Agglomerative\":\n",
    "    plt.title(f\"All the {num_clusters} {clustering_alg} clusters\")\n",
    "    if save_figs == 1:\n",
    "        plt.savefig(f'{output_dir_path}{clustering_alg}_num_clusters_{num_clusters}_linkage_{linkage}_all_Clusters.png')\n",
    "elif clustering_alg == \"Spectral\":\n",
    "    plt.title(f\"All the {num_clusters} {clustering_alg} clusters\")\n",
    "    if save_figs == 1:\n",
    "        plt.savefig(f'{output_dir_path}{clustering_alg}_num_clusters_{num_clusters}_all_Clusters.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting the Features (Principal Component Values)\n",
    "Processing the data and calculating the features can be a time consuming process, especially for huge sets of data. To save the data for later use, you can export it to a CSV file by running the cell that does this. The CSV file will be in the `path_to_csv` directory with the `output_filename` specified previously.\n",
    "\n",
    "The CSV file will contain information for each packet and its principal component values. The columns are specified in the first line of the CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-05T16:08:49.323618349Z",
     "start_time": "2023-07-05T16:08:48.739853098Z"
    }
   },
   "outputs": [],
   "source": [
    "# Exporting the principal component values\n",
    "if save_features == 1:\n",
    "    print('Saving the features File')\n",
    "    traffic_analysis.get_sources_pcs_csv()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster Analysis\n",
    "\n",
    "Different ways of analyzing how the clusters are spread"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster Center Distances\n",
    "Here all the packets in a cluster are used to compute the cluster center (Average). Then the distance from each cluster center to the other Cluster center is computed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Computing Cluster Center Distances\")\n",
    "\n",
    "\n",
    "\n",
    "if num_clusters > 1: \n",
    "    dist_df = pd.DataFrame(np.nan, index=cluster_numbers, columns=cluster_numbers)\n",
    "    \n",
    "    for cluster_n in cluster_numbers:\n",
    "    #     print(f\"cluster_n {cluster_n}\")\n",
    "        current_cluster = pca_values[pca_values['ip'].isin(cluster_dict[cluster_n])]\n",
    "        current_cluster_vals = current_cluster[vals_of_interest]\n",
    "    #     curr_cluster_mean = current_cluster_vals.mean().values.tolist()\n",
    "        curr_cluster_mean = current_cluster_vals.mean().values\n",
    "    #     print('curr_cluster_mean: ', curr_cluster_mean)\n",
    "        dist_df.loc[cluster_n, cluster_n] = 0\n",
    "\n",
    "        if cluster_n < num_clusters-1:\n",
    "\n",
    "            for other_cluster_n in range(cluster_n+1, num_clusters):\n",
    "\n",
    "                other_cluster = pca_values[pca_values['ip'].isin(cluster_dict[other_cluster_n])]\n",
    "                other_cluster_vals = other_cluster[vals_of_interest]\n",
    "                other_cluster_mean = other_cluster_vals.mean().values\n",
    "                cluster_center_dist = euclidean_distances([curr_cluster_mean], [other_cluster_mean]).ravel()\n",
    "                dist_df.loc[cluster_n, other_cluster_n] = cluster_center_dist\n",
    "                dist_df.loc[other_cluster_n, cluster_n] = cluster_center_dist\n",
    "\n",
    "\n",
    "    print(\"\\nCluster Center Distances: Distance from each cluster center (average) to the other cluster centers\")\n",
    "    display(dist_df)\n",
    "else:\n",
    "    print('Only one cluster. No distances to Compute')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Computing Average Cluster Center Distances\")\n",
    "\n",
    "if num_clusters > 1: \n",
    "    for d in range(0, len(dist_df)):\n",
    "        row = dist_df.loc[d, :].to_numpy().nonzero()\n",
    "        non_zero_dists = dist_df.loc[d, row].mean()\n",
    "        print('Cluster: ', d, ' Average Distance to Other Clusters: ', non_zero_dists)\n",
    "else:\n",
    "    print('Only one cluster. No distances to Compute')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster Points Distances\n",
    "Here up to `limit_val` (in config file) packets/source in a cluster are used to compute all the distances from these packets to the packets in other clusters. The distances are then averaged to compute the average distance from a cluster to the other clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Computing Cluster Points Distances\")\n",
    "\n",
    "if num_clusters > 1: \n",
    "    cluster_point_dist_df = pd.DataFrame(np.nan, index=cluster_numbers, columns=cluster_numbers)\n",
    "\n",
    "\n",
    "    for cluster_n in cluster_numbers:\n",
    "        sources = cluster_dict[cluster_n]\n",
    "    #     if debug == 1:\n",
    "    #         print('Processing cluster: ',  cluster_n)\n",
    "\n",
    "        # Find distances between points of current cluster to points in other dists\n",
    "        current_cluster_vals = sample_cluster_pca_vals(vals_of_interest, sources, pca_values, limit_val)\n",
    "        curr_dists = list(euclidean_distances(current_cluster_vals, current_cluster_vals).ravel())\n",
    "        curr_dists =  [d for d in curr_dists if d > 0] # remove the distances from the point to itself\n",
    "        cluster_point_dist_df.loc[cluster_n, cluster_n] = round(np.average(curr_dists), 2)\n",
    "\n",
    "        if cluster_n < num_clusters-1:\n",
    "\n",
    "            for other_cluster_n in range(cluster_n+1, num_clusters):\n",
    "\n",
    "                sources = cluster_dict[other_cluster_n]\n",
    "                other_cluster_vals = sample_cluster_pca_vals(vals_of_interest, sources, pca_values, limit_val)\n",
    "                curr_dists = list(euclidean_distances(current_cluster_vals, other_cluster_vals).ravel())\n",
    "                cluster_point_dist_df.loc[cluster_n, other_cluster_n] = round(np.average(curr_dists), 2)\n",
    "                cluster_point_dist_df.loc[other_cluster_n, cluster_n] = round(np.average(curr_dists), 2)\n",
    "\n",
    "    print(\"\\nCluster Points Distances: averaged distances from packets in one cluster to the packets in other clusters\")\n",
    "    display(cluster_point_dist_df)\n",
    "\n",
    "else:\n",
    "    print('Only one cluster. No distances to Compute')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
